{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccba1cc",
   "metadata": {},
   "source": [
    "Nom1 Prenom1\n",
    "\n",
    "Nom2 Prenom2\n",
    "\n",
    "Nom3 Prenom3\n",
    "\n",
    "(Groupes de 2 à 3 personnes, maximum 4 éventuellement)\n",
    "\n",
    "+changez le titre de ce fichier\n",
    "\n",
    "Inscrivez vous sur: https://docs.google.com/spreadsheets/d/1a9R4jfyLLpy31A4q9z1_va2-HJ6dzYcj-V5SlPTZV-k/edit?usp=sharing\n",
    "(pour éviter d'avoir 2 fois le meme sujet)\n",
    "\n",
    "\n",
    "# Énoncé du projet \n",
    "\n",
    "Les notes de cours imprimées `2022_IAS_notes_de_cours-v3 - pages 1 à 55.pdf` fournissent un guide très détaillé des étapes du projet (pages 25-31). Il y a qq détails qui ne s'appliquent pas pour vous. Par exemple, **je ne vous demande pas de pré-rapport**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7feac",
   "metadata": {},
   "source": [
    "#### Choix du problème \n",
    "\n",
    "Voici quelques suggestions pour choisir votre problème:\n",
    "\n",
    "Globalement, le moteur de recherche https://www.kaggle.com/datasets est quand même bien fait\n",
    "\n",
    "Sinon, quelques idées:\n",
    "- https://www.kaggle.com/nathanlauga/nba-games\n",
    "- https://www.kaggle.com/uciml/student-alcohol-consumption\n",
    "- https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data\n",
    "\n",
    "un peu plus (trop?) facile:\n",
    "- https://www.kaggle.com/spscientist/students-performance-in-exams\n",
    "- https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n",
    "- https://www.kaggle.com/nareshbhat/wine-quality-binary-classification\n",
    "\n",
    "Classif visuelle, mais plutot facile qd meme car du meme genre que MNIST (images très bien pré-traitées)\n",
    "- https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000\n",
    "- https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "\n",
    "Discutés en TD/examen, mais potentiellement bons sujets quand meme:\n",
    "- https://www.kaggle.com/terminus7/pokemon-challenge\n",
    "- https://www.kaggle.com/antoinekrajnc/soccer-players-statistics + https://www.kaggle.com/hugomathien/soccer\n",
    "- https://www.kaggle.com/rahulsridhar2811/cuisine-classification-with-accuracy-78-88\n",
    "- https://www.kaggle.com/mirichoi0218/insurance\n",
    "\n",
    "Et cette base là qui vous permet de filtrer par type de tâche :\n",
    "https://archive.ics.uci.edu/ml/datasets.php\n",
    "Par exemple:\n",
    "https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=num&area=&numAtt=&numIns=&type=uvar&sort=nameUp&view=table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37547c05",
   "metadata": {},
   "source": [
    "## **Encore d'autres idées:**\n",
    "\n",
    "- Déterminer quelle équipe va gagner une game de LoL à partir de matchs classés   https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min\n",
    "- Classifier les genres de musiques   https://www.kaggle.com/mrmorj/dataset-of-songs-in-spotify/tasks?taskId=3062\n",
    "- Prédire la popularité d'une musique https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks\n",
    "- Prédiction du prix d'une voiture en fonction de ses caractéristiques    https://www.kaggle.com/lepchenkov/usedcarscatalog ou encore https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho\n",
    "- Prédiction du genre grace aux données sur sa voix (un peu trop facile)  https://www.kaggle.com/primaryobjects/voicegender\n",
    "- (utilisé en examen, donc pas un bon projet, mais ça peut vous donner des idées)     https://www.kaggle.com/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "- Prédire le nom d'un fruit en fonction d'une image (p-e assez dur ?) https://www.kaggle.com/moltean/fruits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b402f",
   "metadata": {},
   "source": [
    "\n",
    "## A.1. Chargement des données\n",
    "utilisez pandas, typiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87a69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b932a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4efa8e6",
   "metadata": {},
   "source": [
    "## A.2. Exploration préliminaire\n",
    "\n",
    "Jetez un oeil aux données, en tracant par exemple les distributions $P(x_d)$ pour chaque attribut $x_d$, regardez la distribution des $y$ (proportion des classes si c'est une classif, etc).\n",
    "\n",
    "Aide: regardez le code au début de `2022-40-exemple-RegLin-CM.ipynb`, plein de tracés y sont faits. Aussi, dans le code du problème des champignons.\n",
    "\n",
    "Identifiez les attributs qu'il va falloir ré-encoder, les désequilibres potentiels entre les classes, etc.\n",
    "\n",
    "> La première chose à faire consiste à se donner un aperçu des données. En général les datasets fournis en\n",
    "ligne viennent avec une petite présentation et parfois quelques visualisations, mais il est recommandé de faire\n",
    "vous même quelques fonctions permettant d’avoir un aperçu des données/une donnée, afin d’avoir une idée des\n",
    "problèmes qui vont se poser (et comme outil de débug). Vous pouvez aussi utiliser des outils autres (comme\n",
    "t-SNE), sans forcément les maîtriser à fond, dans cette phase exploratoire.\n",
    "Si les données vous semblent de trop mauvaise qualité, ou que la tâche est trop ardue, changez de données!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e52746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf919a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf788117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e8dfd2",
   "metadata": {},
   "source": [
    "## A.3. Définition de la tâche, et choix d’une métrique de performance\n",
    "\n",
    "> Cette partie consiste vraiment à suivre les questions (a,b,c) posées dans le TD 5. Pensez à regarder aussi le\n",
    "corrigé de cet exercice/les exos équivalents dans les annales! Ici on donne quelques idées en plus:\n",
    "Selon la complexité du dataset (estimée lors de la visualisation), viser un objectif non ridicule mais pas trop\n",
    "ambitieux non plus (vous avez relativement peu de temps).\n",
    "Selon le type de tâche ambitionnée (régression ou classification, etc), déterminer une ou des possibilités de\n",
    "“métriques” qui constitueront votre score. Il faut faire attention aux biais dans les données: par exemple si les\n",
    "différentes classes ne sont pas du tout équilibrées, il faut définir une métrique qui donne un poids conséquent y\n",
    "compris aux classes peu fréquentes. Faites un premier choix rapidement, si il s’avère mauvais, vous corrigerez\n",
    "plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73d9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ca938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3de96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e65f95e9",
   "metadata": {},
   "source": [
    "## B.1 Nettoyage (data cleaning), Encodage (encoding) et train-test-validation split\n",
    "\n",
    "Aide: regardez le code dans `2022-101-CM-exemple-encodage-oneHot.ipynb`\n",
    "\n",
    "> Cette partie consiste vraiment à suivre la question (e) posée dans le TD 5. Pensez à regarder aussi le corrigé\n",
    "de cet exercice/les exos équivalents dans les annales! Ici on donne quelques idées en plus:\n",
    ">\n",
    "> Si les données ne sont pas propres, il se peut que vous ayez à les nettoyer. Par exemple, il se peut que\n",
    "certaines valeurs soient manquantes (il faudra alors les remplacer par quelque chose, à choisir, ou modifier\n",
    "l’algorithme d’apprentissage en conséquence). Une autre possibilité est que leur format soit problématique, par\n",
    "exemple des images qui ne sont pas toutes de la même résolution, ou encore pas directement lisibles en python.\n",
    ">\n",
    "> Cette étape peut être réalisée une fois pour toute, en général.\n",
    "\n",
    "Parfois aussi certaines features sont inutiles voire nuisibles, il faut les supprimer à la main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d698cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e458b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399bb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a89e5cb",
   "metadata": {},
   "source": [
    "### Train test split \n",
    "\n",
    "Si vous comptez utiliser la cross vlaidation automatique de sklearn, pas besoin de définir à la main le validation set.\n",
    "Dans ce cas il suffir d'avoir un train set et un test set. Le train set sera découpé de différentes façon lors de la Cross-Validation, et la moyenne sera calculée automatiquement.\n",
    "\n",
    "\n",
    "> C’est aussi le moment de définir le train set, validation set, et test set. Assez souvent, il suffit de mélanger les\n",
    "données (par exemple si MNIST venait avec les chiffres triés dans l’ordre, il faudrait mélanger pour que le test\n",
    "set ne soit pas rempli que de 8 et de 9!). Mais attention, parfois on ne peut pas tout mélanger d’un coup, par\n",
    "exemple si les données sont issues d’une série temporelle et sont donc corrélées, il faut autant que possible laisser\n",
    "ensemble les points proches dans le temps (car corrélés), et séparer les données entre les sets train/validation/test\n",
    "de sorte que ces 3 jeux de données soient indépendants (contiennent des données indépendantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa843ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb747d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c0602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8c50cc",
   "metadata": {},
   "source": [
    "## B.2 Optimisations\n",
    "\n",
    "Aide: regardez les codes dans `2022-91.2-exemple-Optimization1Hyper-param.ipynb` et dans `TP-PCA+SVM-parties1-2-3-enonce.ipynb`\n",
    "\n",
    "> Cette partie consiste à travailler à fond, et donc à expérimenter concrètement sur le choix du modèle (cf. la\n",
    "spéculation demandée en question (e) du TD 5. C’est donc surtout une partie qui fait écho aux exercices 6,\n",
    "et plus particulièrement 6.2,6.3.\n",
    "Cette étape peut être itérée plusieurs fois, selon que vos résultats vous semblent suffisamment satisfaisants.\n",
    "\n",
    "#### 2.1 Architecture\n",
    "> Il va falloir choisir une architecture, c.a.d. le genre de modèle de ML utilisé pour fitter ou modéliser les données (“apprendre” quelque chose).\n",
    ">\n",
    "> On rappelle ici les méthodes qui seront vues en cours (liste approximative):\n",
    "> \n",
    "> Pre-processings:\n",
    "> - standardization\n",
    "> - PCA \n",
    "> - équilibrage des classes (différentes stratégies possibles)\n",
    "> \n",
    "> Algos de classification ou régression:\n",
    "> - Régression (linéaire ou polynomiale)\n",
    "> - Perceptron (à une couche)\n",
    "> - SVC (SVM, pour la Classification)\n",
    "> - SVR (SVM, pour la Regression)\n",
    "> - Decision Trees\n",
    "> - Regression Trees\n",
    "> - Modèle Bayésien Naïf (Bernoulli ou Gauss ou autre) (utile pour la classif de texte)\n",
    "> - K-Nearest Neighbors (classif)\n",
    "> \n",
    "> A combiner avec (Certaines des) méthodes précédentes:\n",
    "> - Feature Maps / Kernels Noyaux -- polynomial, RBF  (Les feature maps peuvent etre vues comme un pre-processing, mais un Kernel doit etre appliqué à la volée).\n",
    "\n",
    "\n",
    "#### 2.2 Choix d’hyper-paramètres\n",
    "\n",
    "> Pour chaque méthode (dans sklearn), il y a en général un certain nombre d’hyper-paramètres associés, qu’il\n",
    "> vous est nécessaire de choisir. Il y a parfois aussi des paramètres de méthode qui servent seulement à imposer la\n",
    "> méthode de résolution numérique du modèle. On ne vous demande pas spécialement d’optimiser ces paramètres\n",
    "> là.\n",
    "> \n",
    "> Remarque/rappel: le choix de l’architecture est en soi un hyper-paramètre. La taille du training set en est\n",
    "> aussi un.\n",
    "> \n",
    "> Lorsque vous chercherez à optimiser des hyper-paramètres, n’oubliez pas :\n",
    "> - De mettre en place une cross-validation\n",
    "> - de tracer les résultats sous forme graphique (et pas seulement afficher des chiffres)\n",
    "> - Ne vous lancez pas dans une recherche systématique sur plus de 2 hyper-paramètres à la fois\n",
    "> - Si les calculs sont très lents, réduisez la taille du train set, mais seulement tant que ça vous coûte peu en termes > de performance.\n",
    "> - Si les calculs sont très lents, envisagez de comprimer les features d’entrée (PCA), même si ça vous coûte un peu en > termes de performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf52ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e003ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dde74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "622c2f06",
   "metadata": {},
   "source": [
    "## C.1 3  Test set, présentation des résultats\n",
    "\n",
    "Vous êtes sûrs de votre coup ? Vous avez bien exploité le validation set, mesuré par cross-validation, estimé l'intervalle d'incertitude ?\n",
    "Ok, allez y sur le test set ! \n",
    "\n",
    "> Pensez à regarder les différentes mesures de scores envisagées au départ sur l’ensemble de validation (une fois\n",
    "> vos hyper-paramètres fixés). Vérifiez qu’il n’y a pas un gros problème que vous n’auriez pas vu. Si les résultats\n",
    "> sont raisonnablement satisfaisants, allez y avec le test set ! (Bref, ne trichez pas lors du test !)\n",
    "> \n",
    "> Lorsque vous présenterez vos résultats (mesures de score, performances), vous mettrez en avant les perfor-\n",
    "> mances sur le test set, mais il est bon de les accompagner des performances mesurées sur le validation set, et\n",
    "> sur le train set, pour permettre de comparer. \n",
    "**(toutes choses égales par ailleurs, évidemment, donc avec les mêmes hyper-paramètres)**\n",
    "> \n",
    "> Pour l’analyse plus qualitative des prédictions, certaines visualisations ne permettent pas de présenter simultanément plusieurs résultats (par exemple si ce sont des images reconstruites, etc). Dans ce cas, privilégiez\n",
    "> toujours le test set.\n",
    "> \n",
    "> Ne vous focalisez pas seulement sur la performance quantitative (la valeur du score), essayez d’analyser la\n",
    "> façon dont les résultats dépendent de vos choix (même si le niveau total n’est “pas très bon”).\n",
    "**Évidemment, si vous voulez présenter l'impact d'un hyper-paramètre sur le score, logiquement, il faut le faire sur le validation set (en tout cas, observer ça sur le test set n'autorise pas à changer d'avis sur les hyper-paramètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243553d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b72760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0dbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0c9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4bf264",
   "metadata": {},
   "source": [
    "## D. Préparez l'oral !!\n",
    "\n",
    "Mais ça ne se passe pas dans un jupyter notebook ! :P\n",
    "\n",
    "voir les pages 28-31 du poly pour des conseils pour l'oral !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c581756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
